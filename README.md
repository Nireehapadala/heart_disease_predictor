# heart_disease_predictor
A machine learning model that predicts the risk of heart disease based on patient data. Built using Python and trained on a public dataset.
A machine learning-based project that predicts the likelihood of heart disease using clinical and lifestyle data. This model is built with algorithms like Logistic Regression, Decision Trees, and Random Forest, trained on a publicly available dataset. The goal is to support early diagnosis and raise awareness of health risks through data-driven insights.

âœ… Key Features:

Data preprocessing and visualization

Multiple classification models

Accuracy comparison and evaluation metrics

Clean, readable code for learning and extension

ðŸš€ Ideal for those interested in ML applications in healthcare and predictive analytics.

ðŸ«€ Heart Disease Predictor
This project uses machine learning to predict the risk of heart disease based on various clinical and personal health factors. Itâ€™s a part of a data science initiative to apply predictive analytics in the healthcare domain.

ðŸ“Œ Project Overview
The aim is to build a classification model that can accurately predict whether a patient is likely to have heart disease, using features like age, sex, chest pain type, blood pressure, cholesterol, and more.

ðŸ§  Technologies Used
Python

Pandas & NumPy â€“ data handling

Matplotlib & Seaborn â€“ data visualization

Scikit-learn â€“ machine learning models and evaluation

ðŸ“‚ Files
heart_model_training.ipynb â€“ Jupyter Notebook containing:

Data loading and exploration

Visualization of feature correlations

Model training (Logistic Regression, Random Forest, Decision Tree)

Accuracy comparison

Final model selection

ðŸ“Š Dataset
The dataset is based on UCI Heart Disease dataset, often used for binary classification problems.

Contains features like:

Age, Sex

Chest Pain Type

Resting BP, Cholesterol

Fasting Blood Sugar

Max Heart Rate, etc.

âœ… Results
Multiple models were trained and evaluated.

Accuracy scores were compared to select the best-performing model.

The Logistic Regression and Random Forest models performed well, with accuracy scores over 85% (based on your code).

ðŸš€ Workflow
1. Data Preprocessing
Loaded dataset

Checked for null values

Encoded categorical variables

Normalised features using StandardScaler

2. Data Visualization
Correlation heatmap to identify important features

Bar plots and histograms for feature distribution

3. Model Building
Trained and evaluated the following algorithms:

Logistic Regression

K-Nearest Neighbors (KNN)

Random Forest

Decision Tree

Support Vector Machine (SVM)

4. Model Evaluation
Accuracy Score

Confusion Matrix

Classification Report

âœ… Results
Model	Accuracy
Logistic Regression	~86%
KNN	~84%
Random Forest	~88%
Decision Tree	~78%
SVM	~85%
ðŸ‘‰ Random Forest achieved the highest accuracy among all tested models.




ðŸ“¬ Contact
Feel free to reach out for suggestions or collaborations!
Author: [Padala Nireeha]
LinkedIn: [www.linkedin.com/in/nireeha-padala-6a71ab2a0]
GitHub: [https://github.com/Nireehapadala]
